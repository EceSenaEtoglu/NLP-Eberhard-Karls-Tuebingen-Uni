# Topic Modeling and Model Comparison on Abstractive Text Summarization

## Tasks

### Task 1: LDA Topic Modeling
- Developed a simple LDA model to identify and visualize latent topics in a dataset.
- Used pyLDAvis for topic visualization.

### Task 2: T5 vs. BART Summarization
- Compared T5 and BART models for abstractive summarization using the EdinburghNLP/xsum dataset, leveraging Hugging Face libraries.
- Conducted parameter tuning but avoided fine-tuning to focus on evaluating the models' base architectures.
- Performance was measured using ROUGE, BERTScore, METEOR, and Human Evaluation.

### Report
- Provided detailed explanations of LDA, T5, and BART architectures, along with an analysis of experimental results.
